{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13630eb5",
   "metadata": {},
   "source": [
    "# 1. Taiwan Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab8e6f6",
   "metadata": {},
   "source": [
    "# 1.1. Taiwan Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bf5308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trish\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_AMT1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('UCI_Credit_Card.csv')\n",
    "\n",
    "# Drop the specified features\n",
    "features_to_drop = ['ID']  # Replace with the features you want to drop\n",
    "data.drop(columns=features_to_drop, inplace=True)\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = data.drop(columns=['default.payment.next.month'])\n",
    "y = data['default.payment.next.month']\n",
    "\n",
    "# Anomaly detection using Isolation Forest before scaling\n",
    "isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "outlier_preds = isolation_forest.fit_predict(X)\n",
    "\n",
    "# Remove outliers\n",
    "X_cleaned = X[outlier_preds == 1]\n",
    "y_cleaned = y[outlier_preds == 1]\n",
    "\n",
    "# Applying Robust Scaling after removing outliers\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_cleaned)\n",
    "\n",
    "# Perform feature selection using information gain\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=5)  # Select top 5 features\n",
    "X_selected = selector.fit_transform(X_scaled, y_cleaned)\n",
    "\n",
    "# Display selected feature names\n",
    "selected_feature_names = X.columns[selector.get_support(indices=True)]\n",
    "print(\"Selected Features:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55b329",
   "metadata": {},
   "source": [
    "# 1.2. Taiwan Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c29da95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "380/380 [==============================] - 9s 10ms/step - loss: 0.3690 - accuracy: 0.8687 - val_loss: 0.2793 - val_accuracy: 0.9090\n",
      "Epoch 2/10\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 0.2632 - accuracy: 0.9155 - val_loss: 0.2665 - val_accuracy: 0.9117\n",
      "Epoch 3/10\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 0.2512 - accuracy: 0.9195 - val_loss: 0.2578 - val_accuracy: 0.9150\n",
      "Epoch 4/10\n",
      "380/380 [==============================] - 3s 8ms/step - loss: 0.2453 - accuracy: 0.9211 - val_loss: 0.2604 - val_accuracy: 0.9133\n",
      "Epoch 5/10\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 0.2424 - accuracy: 0.9206 - val_loss: 0.2522 - val_accuracy: 0.9133\n",
      "Epoch 6/10\n",
      "380/380 [==============================] - 3s 9ms/step - loss: 0.2390 - accuracy: 0.9219 - val_loss: 0.2491 - val_accuracy: 0.9123\n",
      "Epoch 7/10\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 0.2362 - accuracy: 0.9210 - val_loss: 0.2490 - val_accuracy: 0.9140\n",
      "Epoch 8/10\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 0.2337 - accuracy: 0.9223 - val_loss: 0.2445 - val_accuracy: 0.9160\n",
      "Epoch 9/10\n",
      "380/380 [==============================] - 3s 8ms/step - loss: 0.2318 - accuracy: 0.9223 - val_loss: 0.2454 - val_accuracy: 0.9140\n",
      "Epoch 10/10\n",
      "380/380 [==============================] - 3s 7ms/step - loss: 0.2308 - accuracy: 0.9228 - val_loss: 0.2422 - val_accuracy: 0.9143\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9212\n",
      "Test Loss: 0.2292320728302002\n",
      "Test Accuracy: 0.9211705923080444\n",
      "Epoch 1 - Accuracy: 0.868655264377594 - Loss: 0.36899593472480774\n",
      "Epoch 2 - Accuracy: 0.9154581427574158 - Loss: 0.26318901777267456\n",
      "Epoch 3 - Accuracy: 0.919495701789856 - Loss: 0.25123119354248047\n",
      "Epoch 4 - Accuracy: 0.9211437106132507 - Loss: 0.2452741414308548\n",
      "Epoch 5 - Accuracy: 0.9205669164657593 - Loss: 0.24243450164794922\n",
      "Epoch 6 - Accuracy: 0.9218853116035461 - Loss: 0.23899047076702118\n",
      "Epoch 7 - Accuracy: 0.9209789037704468 - Loss: 0.2362259328365326\n",
      "Epoch 8 - Accuracy: 0.9222972989082336 - Loss: 0.23372304439544678\n",
      "Epoch 9 - Accuracy: 0.9222972989082336 - Loss: 0.23182721436023712\n",
      "Epoch 10 - Accuracy: 0.9227917194366455 - Loss: 0.2307872474193573\n",
      "119/119 [==============================] - 2s 3ms/step\n",
      "Overall Accuracy: 0.9211705773793831\n",
      "F1 Score: 0.8715083798882682\n",
      "AUC Score: 0.9447917658786851\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from rotation_forest import RotationForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "# Load the Taiwan Credit Risk dataset\n",
    "df = pd.read_csv('UCI_Credit_Card.csv')\n",
    "df.drop(['PAY_6',  'PAY_5', 'PAY_AMT4', 'PAY_AMT3', 'PAY_AMT6', 'LIMIT_BAL', 'PAY_AMT5', 'PAY_AMT2', 'BILL_AMT1', 'EDUCATION', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT5', 'BILL_AMT6', 'ID', 'BILL_AMT4', 'MARRIAGE', 'AGE', 'SEX'],axis=1, inplace=True)\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop(columns=['default.payment.next.month'])\n",
    "y = df['default.payment.next.month']\n",
    "\n",
    "# Rescale data using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Handle class imbalance using SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_scaled, y)\n",
    "\n",
    "# Convert data to 3D for LSTM input\n",
    "X_reshaped = X_resampled.reshape(X_resampled.shape[0], 1, X_resampled.shape[1])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define LSTM architecture with multiple layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=40, return_sequences=True))\n",
    "model.add(LSTM(units=30, return_sequences=True))\n",
    "model.add(LSTM(units=20))  # Last layer doesn't need return_sequences=True\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Print accuracy and loss of each epoch\n",
    "for epoch, acc in enumerate(history.history['accuracy']):\n",
    "    print(\"Epoch\", epoch+1, \"- Accuracy:\", acc, \"- Loss:\", history.history['loss'][epoch])\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02cba25",
   "metadata": {},
   "source": [
    "# 2. Australian Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184da6b",
   "metadata": {},
   "source": [
    "# 2.1. Australian Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ec533b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Int64Index([6, 7, 8, 9, 13], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('australian.dat', sep=' ', header=None)\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop(columns=[14])\n",
    "y = df[14]\n",
    "\n",
    "\n",
    "# Anomaly detection using Isolation Forest before scaling\n",
    "isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "outlier_preds = isolation_forest.fit_predict(X)\n",
    "\n",
    "# Remove outliers\n",
    "X_cleaned = X[outlier_preds == 1]\n",
    "y_cleaned = y[outlier_preds == 1]\n",
    "\n",
    "# Applying Robust Scaling after removing outliers\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_cleaned)\n",
    "\n",
    "# Perform feature selection using information gain\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=5)  # Select top 5 features\n",
    "X_selected = selector.fit_transform(X_scaled, y_cleaned)\n",
    "\n",
    "# Display selected feature names\n",
    "selected_feature_names = X.columns[selector.get_support(indices=True)]\n",
    "print(\"Selected Features:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bc1241",
   "metadata": {},
   "source": [
    "# 2.2. Australian Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982fe582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 7s 132ms/step - loss: 0.6929 - accuracy: 0.5286 - val_loss: 0.6922 - val_accuracy: 0.4933\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6913 - accuracy: 0.5657 - val_loss: 0.6898 - val_accuracy: 0.6800\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.6970 - val_loss: 0.6828 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6772 - accuracy: 0.8451 - val_loss: 0.6633 - val_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6489 - accuracy: 0.9057 - val_loss: 0.6141 - val_accuracy: 0.9067\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5823 - accuracy: 0.9327 - val_loss: 0.5219 - val_accuracy: 0.9067\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4811 - accuracy: 0.9293 - val_loss: 0.4340 - val_accuracy: 0.9067\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3943 - accuracy: 0.9259 - val_loss: 0.3822 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3395 - accuracy: 0.9394 - val_loss: 0.3477 - val_accuracy: 0.9467\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2957 - accuracy: 0.9495 - val_loss: 0.3209 - val_accuracy: 0.9467\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2862 - accuracy: 0.9570\n",
      "Test Loss: 0.2862035930156708\n",
      "Test Accuracy: 0.9569892287254333\n",
      "Epoch 1 - Accuracy: 0.5286195278167725 - Loss: 0.6928650736808777\n",
      "Epoch 2 - Accuracy: 0.5656565427780151 - Loss: 0.6912654042243958\n",
      "Epoch 3 - Accuracy: 0.6969696879386902 - Loss: 0.6874521970748901\n",
      "Epoch 4 - Accuracy: 0.8451178669929504 - Loss: 0.6771596670150757\n",
      "Epoch 5 - Accuracy: 0.9057239294052124 - Loss: 0.6489147543907166\n",
      "Epoch 6 - Accuracy: 0.932659924030304 - Loss: 0.5823029279708862\n",
      "Epoch 7 - Accuracy: 0.9292929172515869 - Loss: 0.481110543012619\n",
      "Epoch 8 - Accuracy: 0.9259259104728699 - Loss: 0.39432546496391296\n",
      "Epoch 9 - Accuracy: 0.939393937587738 - Loss: 0.339498907327652\n",
      "Epoch 10 - Accuracy: 0.9494949579238892 - Loss: 0.29572516679763794\n",
      "3/3 [==============================] - 2s 4ms/step\n",
      "Overall Accuracy: 0.956989247311828\n",
      "F1 Score: 0.9591836734693877\n",
      "AUC Score: 0.9814814814814814\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from rotation_forest import RotationForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "# Load the dataset\n",
    "df = pd.read_csv('australian.dat', sep=' ', header=None)\n",
    "df.drop([0, 1, 2, 3, 4, 5,  10, 11, 12], axis=1, inplace=True)\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop(columns=[14])\n",
    "y = df[14]\n",
    "\n",
    "# Rescale data using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Handle class imbalance using SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_scaled, y)\n",
    "\n",
    "# Convert data to 3D for LSTM input\n",
    "X_reshaped = X_resampled.reshape(X_resampled.shape[0], 1, X_resampled.shape[1])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define LSTM architecture with multiple layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=40, return_sequences=True))\n",
    "model.add(LSTM(units=30, return_sequences=True))\n",
    "model.add(LSTM(units=20))  # Last layer doesn't need return_sequences=True\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Print accuracy and loss of each epoch\n",
    "for epoch, acc in enumerate(history.history['accuracy']):\n",
    "    print(\"Epoch\", epoch+1, \"- Accuracy:\", acc, \"- Loss:\", history.history['loss'][epoch])\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44fd65",
   "metadata": {},
   "source": [
    "# 3. German Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d37e73",
   "metadata": {},
   "source": [
    "# 3.1. German Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d7e786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Age', 'Sex', 'Saving accounts', 'Duration', 'Purpose'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trish\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('german_credit_data.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(['Unnamed: 0', 'Checking account'], axis=1, inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical form using label encoding\n",
    "le = LabelEncoder()\n",
    "df['Sex'] = le.fit_transform(df['Sex'])\n",
    "df['Housing'] = le.fit_transform(df['Housing'])\n",
    "df['Saving accounts'] = le.fit_transform(df['Saving accounts'])\n",
    "df['Purpose'] = le.fit_transform(df['Purpose'])\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop(columns=['Risk'])\n",
    "y = df['Risk']\n",
    "\n",
    "# Anomaly detection using Isolation Forest before scaling\n",
    "isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "outlier_preds = isolation_forest.fit_predict(X)\n",
    "\n",
    "# Remove outliers\n",
    "X_cleaned = X[outlier_preds == 1]\n",
    "y_cleaned = y[outlier_preds == 1]\n",
    "\n",
    "# Applying Robust Scaling after removing outliers\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_cleaned)\n",
    "\n",
    "# Perform feature selection using information gain\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=5)  # Select top 5 features\n",
    "X_selected = selector.fit_transform(X_scaled, y_cleaned)\n",
    "\n",
    "# Display selected feature names\n",
    "selected_feature_names = X.columns[selector.get_support(indices=True)]\n",
    "print(\"Selected Features:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ee092",
   "metadata": {},
   "source": [
    "# 3.2. German Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2884c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 8s 85ms/step - loss: 0.6122 - accuracy: 0.0098 - val_loss: 0.5238 - val_accuracy: 0.0078\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3813 - accuracy: 0.0039 - val_loss: 0.2382 - val_accuracy: 0.0078\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 10ms/step - loss: -0.1226 - accuracy: 0.0039 - val_loss: -0.5215 - val_accuracy: 0.0078\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 10ms/step - loss: -1.6974 - accuracy: 0.0039 - val_loss: -3.1478 - val_accuracy: 0.0078\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 11ms/step - loss: -6.3938 - accuracy: 0.0039 - val_loss: -8.4024 - val_accuracy: 0.0078\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 10ms/step - loss: -12.5408 - accuracy: 0.0039 - val_loss: -13.2666 - val_accuracy: 0.0078\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 10ms/step - loss: -17.2283 - accuracy: 0.0039 - val_loss: -16.7307 - val_accuracy: 0.0078\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 11ms/step - loss: -20.3071 - accuracy: 0.0039 - val_loss: -19.1204 - val_accuracy: 0.0078\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 12ms/step - loss: -22.3532 - accuracy: 0.0039 - val_loss: -20.8172 - val_accuracy: 0.0078\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 11ms/step - loss: -23.8877 - accuracy: 0.0039 - val_loss: -22.1387 - val_accuracy: 0.0078\n",
      "5/5 [==============================] - 2s 4ms/step - loss: -25.5095 - accuracy: 0.0126\n",
      "Test Loss: -25.509479522705078\n",
      "Test Accuracy: 0.012578615918755531\n",
      "Epoch 1 - Accuracy: 0.009842519648373127 - Loss: 0.6121997237205505\n",
      "Epoch 2 - Accuracy: 0.003937007859349251 - Loss: 0.38130536675453186\n",
      "Epoch 3 - Accuracy: 0.003937007859349251 - Loss: -0.12257333099842072\n",
      "Epoch 4 - Accuracy: 0.003937007859349251 - Loss: -1.6974008083343506\n",
      "Epoch 5 - Accuracy: 0.003937007859349251 - Loss: -6.393825054168701\n",
      "Epoch 6 - Accuracy: 0.003937007859349251 - Loss: -12.540762901306152\n",
      "Epoch 7 - Accuracy: 0.003937007859349251 - Loss: -17.228303909301758\n",
      "Epoch 8 - Accuracy: 0.003937007859349251 - Loss: -20.30708122253418\n",
      "Epoch 9 - Accuracy: 0.003937007859349251 - Loss: -22.353191375732422\n",
      "Epoch 10 - Accuracy: 0.003937007859349251 - Loss: -23.8876895904541\n",
      "5/5 [==============================] - 1s 5ms/step\n",
      "Overall Accuracy: 0.8867924528301887\n",
      "F1 Score: 0.9400000000000001\n",
      "AUC Score: 0.4387312844759653\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the German Credit Risk dataset\n",
    "df = pd.read_csv('german_credit_data.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(['Unnamed: 0', 'Job','Housing','Checking account','Credit amount', 'Risk'], axis=1, inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical form using label encoding\n",
    "le = LabelEncoder()\n",
    "df['Sex'] = le.fit_transform(df['Sex'])\n",
    "#df['Housing'] = le.fit_transform(df['Housing'])\n",
    "#df['Risk'] = le.fit_transform(df['Risk'])\n",
    "df['Saving accounts'] = le.fit_transform(df['Saving accounts'])\n",
    "#df['Checking account'] = le.fit_transform(df['Checking account'])\n",
    "df['Purpose'] = le.fit_transform(df['Purpose'])\n",
    "\n",
    "# Split the dataset into input and output variables\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Rescale data using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Handle class imbalance using SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_scaled, y)\n",
    "\n",
    "# Convert data to 3D for LSTM input\n",
    "X_reshaped = X_resampled.reshape(X_resampled.shape[0], 1, X_resampled.shape[1])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define LSTM architecture with multiple layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=40, return_sequences=True))\n",
    "model.add(LSTM(units=30, return_sequences=True))\n",
    "model.add(LSTM(units=20))  # Last layer doesn't need return_sequences=True\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Print accuracy and loss of each epoch\n",
    "for epoch, acc in enumerate(history.history['accuracy']):\n",
    "    print(\"Epoch\", epoch+1, \"- Accuracy:\", acc, \"- Loss:\", history.history['loss'][epoch])\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Convert y_test to binary labels\n",
    "y_test_binary = (y_test > 0).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "overall_accuracy = accuracy_score(y_test_binary, y_pred)\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test_binary, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc = roc_auc_score(y_test_binary, y_pred_prob)\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5c4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
